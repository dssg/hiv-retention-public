{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sqlalchemy import create_engine\n",
    "import logging\n",
    "import os\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "dburl = os.environ['DBURL']\n",
    "engine = create_engine(dburl)\n",
    "model_comment = 'CDPH_12months_access'\n",
    "path_to_models = '/gpfs/data/dsapp-lab/triage-production_runs_small/trained_models/'\n",
    "path_to_matrices = '/gpfs/data/dsapp-lab/triage-production_runs_small/matrices/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_splits(model_comment):\n",
    "    with open('../../pipeline_CDPH_3.0/analysis/sql/time_splits.sql') as f:\n",
    "        q = f.read()\n",
    "    q = q.replace('model_comment_holder',model_comment)\n",
    "    df_time_split = pd.read_sql(q, engine,\n",
    "                                parse_dates=['train_start_time','train_end_time','test_start_time','test_end_time'])\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    fig, ax = plt.subplots(1,figsize=(18, 12))\n",
    "    sns.set_context(\"poster\", font_scale=0.5, rc={\"lines.linewidth\": 1,\"lines.markersize\":4})\n",
    "    for y, time_val in df_time_split.iterrows():\n",
    "        train_start, train_end, test_start, test_end, train_label_timespan, test_label_timespan = time_val\n",
    "        logging.info('train_end+train_label_timespan: {}+{}={}'.format(train_end,train_label_timespan,train_end+train_label_timespan))\n",
    "        logging.info('train_label_timespan {} test_label_timespan {}'.format(train_label_timespan,test_label_timespan))\n",
    "        _ = plt.plot([train_start,train_end], [y,y],marker='o',color='red')\n",
    "        _ = plt.plot([train_end,train_end+train_label_timespan], [y,y],marker='o',linestyle='--',color='red')\n",
    "        _ = plt.plot([test_start,test_end+test_label_timespan], [y,y],marker='o',linestyle='--',color='blue')\n",
    "    _ = ax.axes.yaxis.set_ticklabels([])\n",
    "    _ = plt.ylabel('time splits')\n",
    "    _ = plt.xlabel('time')\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_model_evaluation(model_group_id, metric, parameter):\n",
    "\n",
    "    q=f\"\"\"select\n",
    "        evaluation_start_time,\n",
    "        value\n",
    "    from\n",
    "        test_results.evaluations\n",
    "    where\n",
    "        model_id in (select distinct model_id from model_metadata.models where model_group_id = {model_group_id}) and\n",
    "        metric = '{metric}' and\n",
    "        parameter = '{parameter}' and\n",
    "        evaluation_end_time < '2046-02-02'::date\n",
    "    order by\n",
    "          evaluation_end_time;\n",
    "\n",
    "    \"\"\"\n",
    "    dfx = pd.read_sql(q,engine,parse_dates=['evaluation_start_time'])\n",
    "    x,y= zip(*dfx.values.tolist())\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot_label(row):\n",
    "    hp = row['hyperparameters']\n",
    "    if row['model_type'] == 'sklearn.ensemble.RandomForestClassifier':\n",
    "        tag ='RF_'+str(row['model_group_id'])+'_n'+str(hp['n_estimators'])+'_d'+str(hp['max_depth'])\n",
    "    elif row['model_type'] == 'sklearn.tree.DecisionTreeClassifier':\n",
    "        tag = 'DT_'+str(row['model_group_id'])+'_d'+str(hp['max_depth'])\n",
    "    elif 'LogisticRegression' in row['model_type']:\n",
    "        tag = 'SLR_'+str(row['model_group_id'])+'_C'+str(hp['C'])+'_p'+str(hp['penalty'])\n",
    "    elif row['model_type'] == 'xgboost.sklearn.XGBClassifier':\n",
    "        tag = 'GB_'+str(row['model_group_id'])+'_n'+str(hp['n_estimators'])+'_d'+str(hp['max_depth'])\n",
    "    elif row['model_type'] == 'sklearn.dummy.DummyClassifier':\n",
    "        tag = 'Dummy'\n",
    "    else:\n",
    "        raise ValueError('Never Seen: '+ row['model_type'])\n",
    "    return tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audition_graph(metric,parameter,ls_model_group_tag,legend=True, color=None):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    fig, ax = plt.subplots(1,figsize=(52, 24))\n",
    "    sns.set_context(\"poster\", font_scale=2., rc={\"lines.linewidth\": 1.25,\"lines.markersize\":18})\n",
    "    _=plt.ylim(0,1)\n",
    "    _=plt.ylabel(f'{metric}:{parameter}')\n",
    "\n",
    "    for model_group_id, tag in ls_model_group_tag:\n",
    "        x,y = grab_model_evaluation(model_group_id,metric,parameter)\n",
    "        if color:\n",
    "            _=plt.plot(x,y, label='model',marker='o',linestyle='-',linewidth=6, color='blue')\n",
    "        else:\n",
    "            _=plt.plot(x,y, label=tag,marker='o',linestyle='-',linewidth=6)\n",
    "\n",
    "\n",
    "    x_baseline, y_baseline = grab_model_evaluation(model_group_id,metric,'100.0_pct')\n",
    "    _=plt.plot(x_baseline,y_baseline, label='baserate',marker='o',linestyle='-',linewidth=6,color='grey')\n",
    "\n",
    "    if legend:\n",
    "        _=plt.legend(bbox_to_anchor=(0., 1.005, 1., .102), loc=7,ncol=6, borderaxespad=0.)\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=\"select * from model_metadata.models where model_comment = '{}';\".format(model_comment)\n",
    "df_models = pd.read_sql(q,engine)\n",
    "df_models['plot_label'] = df_models.apply(lambda x: make_plot_label(x), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mgs_1 = {'sklearn.tree.DecisionTreeClassifier': 21128,\n",
    " 'triage.component.catwalk.estimators.classifiers.ScaledLogisticRegression': 21136,\n",
    " 'sklearn.ensemble.RandomForestClassifier': 21144}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12 Months Access "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mgs_1 = {'sklearn.ensemble.RandomForestClassifier': 21144}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_top1=df_models[df_models['model_group_id'].isin(best_mgs_1.values())]\n",
    "ls_model_group_tag = df_models_top1[['model_group_id','plot_label']].drop_duplicates().values\n",
    "metric = 'precision@'\n",
    "parameter = '1.0_pct'\n",
    "audition_graph(metric,parameter,ls_model_group_tag, color=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_splits(model_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#production figure\n",
    "df_models_top1=df_models[df_models['model_group_id'].isin(best_mgs_1.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models[df_models.model_group_id == 21144]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_features = \"select * from train_results.feature_importances where model_id = 94982 order by feature_importance desc;\"\n",
    "df_features_94982 = pd.read_sql(q_features,engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_94982.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_94982['feature_group'] = df_features_94982.feature.apply(lambda x: x.split('_')[0])\n",
    "\n",
    "df_feature_sum = df_features_94982[['feature_group','feature_importance']].groupby('feature_group').mean()\n",
    "\n",
    "df_feature_sum = df_feature_sum.reset_index()\n",
    "\n",
    "dict_english_mapping = {'cd4': 'cd4 tests',\n",
    "                        'demographics': 'demographics',\n",
    "                        'dxstatus': 'diagnosis status',\n",
    "                        'location': 'location',\n",
    "                       'prevappts': 'previous appointment history',\n",
    "                       'trancateg': 'transmission category',\n",
    "                        'vl': 'viral load tests'}\n",
    "\n",
    "df_feature_sum['feature'] = df_feature_sum.reset_index()['feature_group'].apply(lambda x: dict_english_mapping[x])\n",
    "df_feature_sum = df_feature_sum.set_index('feature')\n",
    "fig, ax = plt.subplots(1,figsize=(12, 5))\n",
    "sns.set_context(\"poster\", font_scale=1.25, rc={\"lines.linewidth\": 1.25,\"lines.markersize\":8})\n",
    "df_feature_sum['feature_importance'].sort_values(ascending=True).plot(kind='barh', xlim=(0,.05))\n",
    "plt.ylabel('relative avg importance\\n of a feature class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_sum['feature_importance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from triage.component.postmodeling.contrast.utils.aux_funcs import create_pgconn, get_models_ids\n",
    "from triage.component.catwalk.storage import ProjectStorage, ModelStorageEngine, MatrixStorageEngine\n",
    "from triage.component.postmodeling.contrast.parameters import PostmodelParameters\n",
    "from triage.component.postmodeling.contrast.model_evaluator import ModelEvaluator\n",
    "from triage.component.postmodeling.contrast.model_group_evaluator import ModelGroupEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelevaluation  = ModelEvaluator(21144, 94982, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelevaluation.plot_precision_recall_n(figsize=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelevaluation.plot_precision_recall_n(figsize=(12,12), xlim=[0,0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Month Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comment = 'CDPH_6months_access_memo'\n",
    "q=\"select * from model_metadata.models where model_comment = '{}';\".format(model_comment)\n",
    "df_models = pd.read_sql(q,engine)\n",
    "df_models['plot_label'] = df_models.apply(lambda x: make_plot_label(x), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mgs_1 = {'sklearn.ensemble.RandomForestClassifier': 21157}\n",
    "df_models_top1=df_models[df_models['model_group_id'].isin(best_mgs_1.values())]\n",
    "ls_model_group_tag = df_models_top1[['model_group_id','plot_label']].drop_duplicates().values\n",
    "metric = 'precision@'\n",
    "parameter = '1.0_pct'\n",
    "audition_graph(metric,parameter,ls_model_group_tag, color=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_time_splits(model_comment='CDPH_6months_access_memo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_features = \"select * from train_results.feature_importances where model_id = 96042 order by feature_importance desc;\"\n",
    "df_features_96042 = pd.read_sql(q_features,engine)\n",
    "df_features_96042.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_96042['feature_group'] = df_features_96042.feature.apply(lambda x: x.split('_')[0])\n",
    "\n",
    "df_feature_sum = df_features_96042[['feature_group','feature_importance']].groupby('feature_group').mean()\n",
    "\n",
    "df_feature_sum = df_feature_sum.reset_index()\n",
    "\n",
    "dict_english_mapping = {'cd4': 'cd4 tests',\n",
    "                        'demographics': 'demographics',\n",
    "                        'dxstatus': 'diagnosis status',\n",
    "                        'location': 'location',\n",
    "                       'prevappts': 'previous appointment history',\n",
    "                       'trancateg': 'transmission category',\n",
    "                        'vl': 'viral load tests'}\n",
    "\n",
    "df_feature_sum['feature'] = df_feature_sum.reset_index()['feature_group'].apply(lambda x: dict_english_mapping[x])\n",
    "df_feature_sum = df_feature_sum.set_index('feature')\n",
    "fig, ax = plt.subplots(1,figsize=(12, 5))\n",
    "sns.set_context(\"poster\", font_scale=1.5, rc={\"lines.linewidth\": 1.25,\"lines.markersize\":8})\n",
    "df_feature_sum['feature_importance'].sort_values(ascending=True).plot(kind='barh', xlim=(0,.05))\n",
    "plt.ylabel('relative avg importance\\n of a feature class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_sum['feature_importance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelevaluation  = ModelEvaluator(21157, 96042, engine)\n",
    "modelevaluation.plot_precision_recall_n(figsize=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelevaluation.plot_precision_recall_n(figsize=(12,12), xlim=[0,0.05])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
